{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Meta Learning with implicit gradients[author paper random dataset]",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6F74pLM66dNt"
      },
      "source": [
        "## Gradient Checkpointing Model-Agnostic Meta-Learning\n",
        "\n",
        "We demonstrate how to use memory efficient MAML on CIFAR10.\n",
        "This notebook performs one forward and backward for MAML with a large number of iterations\n",
        "\n",
        "* Data: Random tensors (batch_size, 3, 224, 224)  \n",
        "* Model: ResNet18\n",
        "* Optimizer: SGD with 0.01 learning rate\n",
        "* Batch size: 16\n",
        "* MAML steps: 100 (works with >500 on 11GB GPU)\n",
        "* GPU: whatever colab has to spare, probably K80"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "is_executing": true
        },
        "id": "alrX0irZ6dNv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f0908587-e941-4797-b6bc-c36d6b43447d"
      },
      "source": [
        "%env CUDA_VISIBLE_DEVICES=0\n",
        "# colab dependencies\n",
        "!pip install torch==1.3.1 torchvision==0.4.2 torch_maml\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import torch, torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision.models as models\n",
        "\n",
        "import torch_maml\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "# For reproducibility\n",
        "import random\n",
        "random.seed(42)\n",
        "np.random.seed(42)\n",
        "torch.manual_seed(42)\n",
        "\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmarks = False"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "env: CUDA_VISIBLE_DEVICES=0\n",
            "Collecting torch==1.3.1\n",
            "  Downloading torch-1.3.1-cp37-cp37m-manylinux1_x86_64.whl (734.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 734.6 MB 15 kB/s \n",
            "\u001b[?25hCollecting torchvision==0.4.2\n",
            "  Downloading torchvision-0.4.2-cp37-cp37m-manylinux1_x86_64.whl (10.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 10.2 MB 8.6 MB/s \n",
            "\u001b[?25hCollecting torch_maml\n",
            "  Downloading torch_maml-1.0.tar.gz (9.7 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch==1.3.1) (1.19.5)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from torchvision==0.4.2) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from torchvision==0.4.2) (1.15.0)\n",
            "Building wheels for collected packages: torch-maml\n",
            "  Building wheel for torch-maml (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch-maml: filename=torch_maml-1.0-py3-none-any.whl size=9392 sha256=7d5f0dd144e89d9cad9ae7bb4f9138e80f9f981943001ed2a6a758ecaa5bb5b3\n",
            "  Stored in directory: /root/.cache/pip/wheels/6d/99/30/1894147ba887f41ae4b4d39ff75584b2c5fa016f35a22eeca8\n",
            "Successfully built torch-maml\n",
            "Installing collected packages: torch, torchvision, torch-maml\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.10.0+cu111\n",
            "    Uninstalling torch-1.10.0+cu111:\n",
            "      Successfully uninstalled torch-1.10.0+cu111\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.11.1+cu111\n",
            "    Uninstalling torchvision-0.11.1+cu111:\n",
            "      Successfully uninstalled torchvision-0.11.1+cu111\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchtext 0.11.0 requires torch==1.10.0, but you have torch 1.3.1 which is incompatible.\n",
            "torchaudio 0.10.0+cu111 requires torch==1.10.0, but you have torch 1.3.1 which is incompatible.\u001b[0m\n",
            "Successfully installed torch-1.3.1 torch-maml-1.0 torchvision-0.4.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mx7mOCc76dNz"
      },
      "source": [
        "#### Define compute_loss function and create model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EOvFGH9W6dN0"
      },
      "source": [
        "# Interface:\n",
        "# def compute_loss(model, data, **kwargs):\n",
        "#      <YOUR CODE HERE>  # ideally this should be stateless (does not change global variables)\n",
        "#      return loss\n",
        "\n",
        "# Our example\n",
        "def compute_loss(model, data, device='cuda'):\n",
        "    inputs, targets = data\n",
        "    preds = model(inputs.to(device=device))\n",
        "    loss = F.cross_entropy(preds, targets.to(device=device))\n",
        "    return loss"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WwFkRoBP6dN2"
      },
      "source": [
        "# Model is a torch.nn.Module \n",
        "model = models.resnet18(num_classes=10).to(device)\n",
        "# Optimizer is a custom MAML optimizer, e.g. SGD\n",
        "optimizer = torch_maml.IngraphGradientDescent(learning_rate=0.01)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cti7QScs6dN4"
      },
      "source": [
        "#### Create NaiveMAML and GradientCheckpointMAML for comparison"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "35otHsPc6dN4"
      },
      "source": [
        "efficient_maml = torch_maml.GradientCheckpointMAML(\n",
        "    model, compute_loss, optimizer=optimizer, checkpoint_steps=5)\n",
        "\n",
        "naive_maml = torch_maml.NaiveMAML(model, compute_loss, optimizer=optimizer)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nQxlYGRR6dN6"
      },
      "source": [
        "#### Sanity check: small number of steps\n",
        "\n",
        "Both naive and memory-efficient maml should produce the same output."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I9KfEdYL6dN6"
      },
      "source": [
        "# First, we set such max steps that fits memory for naive MAML to check the implementation\n",
        "maml_steps = 10\n",
        "\n",
        "# Clip meta-learning gradients by global norm to avoid explosion\n",
        "max_grad_grad_norm = 1e2"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZpSyUhuk6dN9"
      },
      "source": [
        "# Generate batch for demonstration. Note that we support using different batches for each MAML step (a-la SGD)\n",
        "x_batch, y_batch = torch.randn((16, 3, 224, 224)), torch.randint(0, 10, (16, ))\n",
        "inputs = [(x_batch, y_batch)] * maml_steps  # use the same batch for each step"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T5hbRPIM6dN_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b3cb5887-da7c-448e-dc75-0d4ac11cda70"
      },
      "source": [
        "updated_model, loss_history, _ = naive_maml(inputs, loss_kwargs={'device':device},\n",
        "                                            max_grad_grad_norm=max_grad_grad_norm)\n",
        "final_loss = compute_loss(updated_model, (x_batch, y_batch), device=device)\n",
        "final_loss.backward()\n",
        "grads_naive = [params.grad for params in model.parameters()]\n",
        "print(\"Loss naive: %.4f\" % final_loss.item())"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss naive: 0.5537\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j2G812Bs6dOA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eb3cd747-570c-4a4a-c84f-55af05c533e0"
      },
      "source": [
        "updated_model, loss_history, _ = efficient_maml(inputs, loss_kwargs={'device':device},\n",
        "                                                max_grad_grad_norm=max_grad_grad_norm)\n",
        "final_loss = compute_loss(updated_model, (x_batch, y_batch), device=device)\n",
        "final_loss.backward()\n",
        "grads_efficient = [params.grad for params in model.parameters()]\n",
        "print(\"Loss memory-efficient: %.4f\" % final_loss.item())"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss memory-efficient: 0.5537\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lTnR_KFM6dOC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7bfb7aa3-3f2f-4d30-acdd-e6c9b5a38363"
      },
      "source": [
        "for grad1, grad2 in zip(grads_naive, grads_efficient):\n",
        "    assert torch.allclose(grad1, grad2)\n",
        "\n",
        "print(\"All grads match!\")"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All grads match!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8XfRGRhq6dOD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d3d89ce4-8ea9-49cb-b640-64e54cbb05e0"
      },
      "source": [
        "# alternative: use rmsprop optimizer\n",
        "rmsprop_maml = torch_maml.GradientCheckpointMAML(\n",
        "    model, compute_loss, optimizer=torch_maml.IngraphRMSProp(learning_rate=1e-3, beta=0.9, epsilon=1e-5), \n",
        "    checkpoint_steps=5)\n",
        "\n",
        "updated_model, loss_history, _ = rmsprop_maml(inputs, loss_kwargs={'device':device},\n",
        "                                                max_grad_grad_norm=max_grad_grad_norm)\n",
        "final_loss = compute_loss(updated_model, (x_batch, y_batch), device=device)\n",
        "final_loss.backward()\n",
        "grads_efficient = [params.grad for params in model.parameters()]\n",
        "print(\"Loss RMSProp: %.4f\" % final_loss.item())"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss RMSProp: 0.0224\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t13US_Vn6dOF"
      },
      "source": [
        "### The real meta-learning: 100 steps and beyond"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gUk7JFIm6dOG"
      },
      "source": [
        "maml_steps = 100  # feel free to tweak (works with >500)\n",
        "inputs = [(x_batch, y_batch)] * maml_steps\n",
        "torch.cuda.empty_cache()"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qx4yJPAJ6dOH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        },
        "outputId": "dc50f61f-09cb-41c4-fc18-03900f8abc94"
      },
      "source": [
        "updated_model, loss_history, _ = efficient_maml(inputs, loss_kwargs={'device':device},\n",
        "                                        max_grad_grad_norm=max_grad_grad_norm)\n",
        "final_loss = compute_loss(updated_model, (x_batch, y_batch), device=device)\n",
        "final_loss.backward()\n",
        "grads_efficient = [params.grad for params in model.parameters()]\n",
        "\n",
        "plt.plot(loss_history)\n",
        "print(\"Loss memory-efficient: %.4f\" % final_loss.item())"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss memory-efficient: 0.0427\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}